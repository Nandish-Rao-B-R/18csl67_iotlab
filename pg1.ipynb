{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de20e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Set:\n",
      "['sunny', 'warm', 'normal', 'strong', 'warm', 'same', 'yes']\n",
      "['sunny', 'warm', 'high', 'strong', 'warm', 'same', 'yes']\n",
      "['rainy', 'cold', 'high', 'strong', 'warm', 'change', 'no']\n",
      "['sunny', 'warm', 'high', 'strong', 'cold', 'change', 'yes']\n",
      "\n",
      " Find -S Algorithm\n",
      " Intialize h to most specific hypothesis\n",
      " \n",
      "h= ['0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "example: 1 is the postive example, cgange hypothesis\n",
      "h= ['sunny', 'warm', 'normal', 'strong', 'warm', 'same'] \n",
      "\n",
      "example: 2 is the postive example, cgange hypothesis\n",
      "h= ['sunny', 'warm', '?', 'strong', 'warm', 'same'] \n",
      "\n",
      "exampl 3 is negative,do nothing\n",
      "h= ['sunny', 'warm', '?', 'strong', 'warm', 'same'] \n",
      "\n",
      "example: 4 is the postive example, cgange hypothesis\n",
      "h= ['sunny', 'warm', '?', 'strong', '?', '?'] \n",
      "\n",
      "Maximally specific  hypothesis h= ['sunny', 'warm', '?', 'strong', '?', '?']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('./file1.csv','r')as f:\n",
    "    readdata=csv.reader(f)\n",
    "    ds=list(readdata)\n",
    "print(\"Training Data Set:\")\n",
    "for row in ds:\n",
    "    print(row)\n",
    "atl=len(ds[0])-1\n",
    "h=['0']*atl\n",
    "print(\"\\n Find -S Algorithm\\n Intialize h to most specific hypothesis\\n \")\n",
    "print(\"h=\",h,\"\\n\")\n",
    "i=1\n",
    "for row in ds:\n",
    "    if row[-1]==\"yes\":\n",
    "        print(\"example:\",i,\"is the postive example, cgange hypothesis\" )\n",
    "        j=0\n",
    "        for col in row:\n",
    "          if col!=\"yes\": \n",
    "        if col!=h[j] and h[j]=='0':\n",
    "                h[j]=col\n",
    "            elif col!=h[j] and h[j]!='0':\n",
    "                h[j]='?'\n",
    "            j=j+1\n",
    "    else:\n",
    "        print(\"exampl\",i,\"is negative,do nothing\")\n",
    "    print(\"h=\",h,\"\\n\")\n",
    "    i=i+1\n",
    "print(\"Maximally specific  hypothesis h=\",h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56388e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "with open(\"C://1DA20CS419//file2.csv\",\"w\",newline=\"\")as f:\n",
    "    data=csv.writer(f)\n",
    "    data.writerow([\"sunny\",\"warm\",\"normal\",\"strong\",\"warm\",\"same\",\"ÿes\"])\n",
    "    data.writerow([\"sunny\",\"warm\",\"high\",\"strong\",\"warm\",\"same\",\"ÿes\"])\n",
    "    data.writerow([\"rainy\",\"cold\",\"high\",\"strong\",\"warm\",\"change\",\"no\"])\n",
    "    data.writerow([\"sunny\",\"warm\",\"high\",\"strong\",\"cold\",\"change\",\"ÿes\"])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f895e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./file3.csv','r')as f:\n",
    "    readdata=csv.reader(f)\n",
    "    data=list(readdata)\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "print(\"\\nInstances are:\\n\",concepts)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "print(\"\\nTarget Values are: \",target)\n",
    "\n",
    "def learn(concepts, target): \n",
    "    specific_h = concepts[0].copy()\n",
    "    print(\"\\nInitialization of specific_h and genearal_h\")\n",
    "    print(\"\\nSpecific Boundary: \", specific_h)\n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
    "    print(\"\\nGeneric Boundary: \",general_h)  \n",
    "\n",
    "    for i, h in enumerate(concepts):\n",
    "        print(\"\\nInstance\", i+1 , \"is \", h)\n",
    "        if target[i] == \"yes\":\n",
    "            print(\"Instance is Positive \")\n",
    "            for x in range(len(specific_h)): \n",
    "                if h[x]!= specific_h[x]:                    \n",
    "                    specific_h[x] ='?'                     \n",
    "                    general_h[x][x] ='?'\n",
    "                   \n",
    "        if target[i] == \"no\":            \n",
    "            print(\"Instance is Negative \")\n",
    "            for x in range(len(specific_h)): \n",
    "                if h[x]!= specific_h[x]:                    \n",
    "                    general_h[x][x] = specific_h[x]                \n",
    "                else:                    \n",
    "                    general_h[x][x] = '?'        \n",
    "        \n",
    "        print(\"Specific Bundary after \", i+1, \"Instance is \", specific_h)         \n",
    "        print(\"Generic Boundary after \", i+1, \"Instance is \", general_h)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]    \n",
    "    for i in indices:   \n",
    "        general_h.remove(['?', '?', '?', '?', '?', '?']) \n",
    "    return specific_h, general_h \n",
    "\n",
    "s_final, g_final = learn(concepts, target)\n",
    "\n",
    "print(\"Final Specific_h: \", s_final, sep=\"\\n\")\n",
    "print(\"Final General_h: \", g_final, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be883372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "datalist=[[\"sunny\",\"warm\",\"normal\",\"strong\",\"warm\",\"same\",\"ÿes\"], [\"sunny\",\"warm\",\"high\",\"strong\",\"warm\",\"same\",\"ÿes\"],[\"rainy\",\"cold\",\"high\",\"strong\",\"warm\",\"change\",\"no\"],[\"sunny\",\"warm\",\"high\",\"strong\",\"cold\",\"change\",\"ÿes\"]]\n",
    "with open(\"C://1DA20CS419//file1.csv\",\"w\",newline=\"\")as f:\n",
    "          data=csv.writer(f)\n",
    "          data.writerows(datalist)\n",
    "          f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65cdf493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Jang', 'Punjab', 'Amritsar', 'yes'], ['The Nation', 'Punjab', 'Delhi', 'no'], ['Jang', 'India', 'Karnataka', 'no'], ['The Nation', 'Sindh', 'Delhi', 'yes']]\n",
      "\n",
      "The total number of training instances are :  4\n",
      "\n",
      "The initial hypothesis is : \n",
      "['0', '0', '0']\n",
      "\n",
      "Instance  1 is ['Jang', 'Punjab', 'Amritsar', 'yes']  and is Positive Instance\n",
      "The hypothesis for the training instance 1  is:  ['Jang', 'Punjab', 'Amritsar'] \n",
      "\n",
      "\n",
      "Instance  2 is ['The Nation', 'Punjab', 'Delhi', 'no']  and is Negative Instance Hence Ignored\n",
      "The hypothesis for the training instance 2  is:  ['Jang', 'Punjab', 'Amritsar'] \n",
      "\n",
      "\n",
      "Instance  3 is ['Jang', 'India', 'Karnataka', 'no']  and is Negative Instance Hence Ignored\n",
      "The hypothesis for the training instance 3  is:  ['Jang', 'Punjab', 'Amritsar'] \n",
      "\n",
      "\n",
      "Instance  4 is ['The Nation', 'Sindh', 'Delhi', 'yes']  and is Positive Instance\n",
      "The hypothesis for the training instance 4  is:  ['?', '?', '?'] \n",
      "\n",
      "\n",
      "The Maximally specific hypothesis for the training instance is  ['?', '?', '?']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "a = []\n",
    "with open('./file3.csv','r')as  csvfile:\n",
    "    next(csvfile)\n",
    "    for row in csv.reader(csvfile):\n",
    "        a.append(row)\n",
    "    print(a)\n",
    "\n",
    "print(\"\\nThe total number of training instances are : \",len(a))\n",
    "\n",
    "num_attribute = len(a[0])-1\n",
    "\n",
    "print(\"\\nThe initial hypothesis is : \")\n",
    "hypothesis = ['0']*num_attribute\n",
    "print(hypothesis)\n",
    "\n",
    "for i in range(0, len(a)):\n",
    "    if a[i][num_attribute] == 'yes':\n",
    "        print (\"\\nInstance \", i+1, \"is\", a[i], \" and is Positive Instance\")\n",
    "        for j in range(0, num_attribute):\n",
    "            if hypothesis[j] == '0' or hypothesis[j] == a[i][j]:\n",
    "                hypothesis[j] = a[i][j]\n",
    "            else:\n",
    "                hypothesis[j] = '?'\n",
    "        print(\"The hypothesis for the training instance\", i+1, \" is: \" , hypothesis, \"\\n\")\n",
    "\n",
    "    if a[i][num_attribute] == 'no':\n",
    "        print (\"\\nInstance \", i+1, \"is\", a[i], \" and is Negative Instance Hence Ignored\")\n",
    "        print(\"The hypothesis for the training instance\", i+1, \" is: \" , hypothesis, \"\\n\")\n",
    "\n",
    "print(\"\\nThe Maximally specific hypothesis for the training instance is \", hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ec640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "df_tennis = pd.read_csv('id3.csv')\n",
    "target = df_tennis.keys()[-1]\n",
    "attributes=list(df_tennis.keys())\n",
    "attributes.remove(target)\n",
    "\n",
    "def entropy_list(alist):\n",
    "    from collections import Counter\n",
    "    cnt = Counter(x for x in alist)\n",
    "    #cnt=Counter(len(alist))\n",
    "    nobs=len(alist)*1.0\n",
    "    probs=[x/nobs for x in cnt.values()]\n",
    "    return entropy(probs)\n",
    "\n",
    "def entropy(probs):\n",
    "    return sum([-prob*math.log(prob,2) for prob in probs])\n",
    "\n",
    "def info_gain(df,split,target):\n",
    "    df_split=df.groupby(split)\n",
    "    nobs=len(df.index)*1.0\n",
    "    df_agg_ent = df_split.agg({target : [entropy_list,lambda x : len(x)/nobs]})[target]\n",
    "    df_agg_ent.columns=['Entropy','propObservations']\n",
    "    new_entropy = sum(df_agg_ent['Entropy']*df_agg_ent['propObservations'])\n",
    "    old_entropy = entropy_list(df[target])\n",
    "    return old_entropy - new_entropy\n",
    "\n",
    "def id3(df,target,attributes,default_class=None):\n",
    "    from collections import Counter\n",
    "    cnt = Counter(df[target])\n",
    "    if len(cnt)==1:\n",
    "        return next(iter(cnt))\n",
    "    elif df.empty or (not attributes):\n",
    "        return default_class\n",
    "    else:\n",
    "        default_class=max(cnt.keys())\n",
    "        gainz=[]\n",
    "        print(attributes)\n",
    "        gainz=[info_gain(df,attr,target) for attr in attributes]\n",
    "        indexofmax=gainz.index(max(gainz))\n",
    "        bestattr = attributes[indexofmax]\n",
    "        tree={bestattr:{}}\n",
    "        remaining_attr = [x for x in attributes if x!=bestattr]\n",
    "        for attr,subset in df.groupby(bestattr):\n",
    "            subtree=id3(subset,target,remaining_attr,default_class)\n",
    "            tree[bestattr][attr]=subtree\n",
    "        return tree\n",
    "\n",
    "tree=id3(df_tennis,target,attributes)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9574ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
